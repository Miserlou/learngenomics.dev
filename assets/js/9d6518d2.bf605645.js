"use strict";(self.webpackChunklearngenomics_dev=self.webpackChunklearngenomics_dev||[]).push([[453],{3905:function(e,n,a){a.d(n,{Zo:function(){return d},kt:function(){return u}});var t=a(7294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function s(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),c=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},d=function(e){var n=c(e.components);return t.createElement(l.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},p=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(a),u=r,f=p["".concat(l,".").concat(u)]||p[u]||m[u]||i;return a?t.createElement(f,o(o({ref:n},d),{},{components:a})):t.createElement(f,o({ref:n},d))}));function u(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=p;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=a[c];return t.createElement.apply(null,o)}return t.createElement.apply(null,a)}p.displayName="MDXCreateElement"},1659:function(e,n,a){a.r(n),a.d(n,{assets:function(){return d},contentTitle:function(){return l},default:function(){return u},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return m}});var t=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={title:"Worked Example",track:"Engineering Ecosystem"},l=void 0,c={unversionedId:"engineering-ecosystem/end-to-end-example",id:"engineering-ecosystem/end-to-end-example",title:"Worked Example",description:"The following guide is intended to be a simple end-to-end workflow you can run",source:"@site/docs/05-engineering-ecosystem/03-end-to-end-example.md",sourceDirName:"05-engineering-ecosystem",slug:"/engineering-ecosystem/end-to-end-example",permalink:"/docs/engineering-ecosystem/end-to-end-example",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/05-engineering-ecosystem/03-end-to-end-example.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"Worked Example",track:"Engineering Ecosystem"},sidebar:"tutorialSidebar",previous:{title:"Common Genomics Tools",permalink:"/docs/engineering-ecosystem/common-genomics-tools"},next:{title:"Advanced Topics",permalink:"/docs/advanced-topics/"}},d={},m=[{value:"Environment",id:"environment",level:2},{value:"Acquire sequencing data",id:"acquire-sequencing-data",level:2},{value:"Verifying sequencing data",id:"verifying-sequencing-data",level:2},{value:"Download the reference genome",id:"download-the-reference-genome",level:2},{value:"Index the reference genome",id:"index-the-reference-genome",level:2},{value:"Aligning reads",id:"aligning-reads",level:2},{value:"Postprocessing",id:"postprocessing",level:2},{value:"Coordinate sort",id:"coordinate-sort",level:3},{value:"Mark duplicates",id:"mark-duplicates",level:3},{value:"Index the BAM file",id:"index-the-bam-file",level:3},{value:"Sanity Flagstat Check",id:"sanity-flagstat-check",level:3},{value:"Piling up variants",id:"piling-up-variants",level:2},{value:"Number of variants",id:"number-of-variants",level:2},{value:"Download IGV",id:"download-igv",level:2}],p={toc:m};function u(e){var n=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,t.Z)({},p,a,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"The following guide is intended to be a simple end-to-end workflow you can run\nat home to understand some of the core concepts in this guide. The entire\nanalysis was performed on a machine with the following specs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"CPU")," \u2014 Intel Core i7-9700K CPU @ 3.60GHz (8 cores)"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"RAM")," \u2014 2x16GB Corsair Vengeance DDR4 3000MHz"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"SSD")," \u2014 Samsung 860 EVO 1TB SATA III")),(0,i.kt)("p",null,"Additionally, you will need the following minimum requirements to complete this\nexercise."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"~60GB of free disk space."),(0,i.kt)("li",{parentName:"ul"},"8GB+ of RAM.")),(0,i.kt)("h2",{id:"environment"},"Environment"),(0,i.kt)("p",null,"We use ",(0,i.kt)("a",{parentName:"p",href:"https://anaconda.com"},"anaconda")," and more specifically\n",(0,i.kt)("a",{parentName:"p",href:"https://bioconda.github.io/"},"bioconda")," for simple dependency management. Please\nfollow the ",(0,i.kt)("a",{parentName:"p",href:"https://docs.anaconda.com/anaconda/install/"},"installation\ninstructions")," and\nbootstrap your environment by running the following commands:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash{numberLines:",metastring:"1}","1}":!0},"conda create -n worked-example -c bioconda bcftools==1.9 bwa==0.7.17 fastqc==0.11.8 samtools==1.9 picard==2.21.2 -y\nconda activate worked-example\n\ncargo install --git https://github.com/stjude/fqlib.git\n")),(0,i.kt)("h2",{id:"acquire-sequencing-data"},"Acquire sequencing data"),(0,i.kt)("p",null,"Next, you'll need some sequencing data. The ",(0,i.kt)("a",{parentName:"p",href:"https://www.internationalgenome.org/"},"1000 genomes\nproject")," graciously hosts all of the FASTQ\nfiles generated as part of the project for the public to download. Typically,\none might combine multiple FASTQ files from the same sample together to have\nsufficient of evidence for calls (you can view an example directory of files\n",(0,i.kt)("a",{parentName:"p",href:"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00133/sequence_read/"},"here"),").\nTo keep computation time small for this example, we will download only a single\npair of FASTQ files."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00133/sequence_read/SRR038564_{1,2}.filt.fastq.gz\n")),(0,i.kt)("h2",{id:"verifying-sequencing-data"},"Verifying sequencing data"),(0,i.kt)("p",null,"Once you've downloaded the file, it's a good idea to run some quick sanity\nchecks. Here, we use ",(0,i.kt)("inlineCode",{parentName:"p"},"fq lint")," to ensure the FASTQ pair is well-formed and\n",(0,i.kt)("inlineCode",{parentName:"p"},"fastqc")," to see how well the sequencing experiment went."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"fq lint SRR038564_1.filt.fastq.gz SRR038564_2.filt.fastq.gz && echo 'Successfully verified FASTQs.' || echo 'Failed to verify FASTQs!'\n# Successfully verified FASTQs.\n\nfastqc -t `nproc` SRR038564_1.filt.fastq.gz SRR038564_2.filt.fastq.gz\n# Started analysis of SRR038564_1.filt.fastq.gz\n# Started analysis of SRR038564_2.filt.fastq.gz\n# Approx 5% complete for SRR038564_1.filt.fastq.gz\n# Approx 5% complete for SRR038564_2.filt.fastq.gz\n#\n# ----------------------\n# | Abbreviated output |\n# ----------------------\n#\n# Approx 95% complete for SRR038564_1.filt.fastq.gz\n# Approx 95% complete for SRR038564_2.filt.fastq.gz\n# Analysis complete for SRR038564_1.filt.fastq.gz\n# Analysis complete for SRR038564_2.filt.fastq.gz\n\nopen SRR038564_{1,2}.filt_fastqc.html\n")),(0,i.kt)("h2",{id:"download-the-reference-genome"},"Download the reference genome"),(0,i.kt)("p",null,"Now that we have our sequencing data, we'll need to download the reference\ngenome which our analyses will be based off of. In this case, we will use the\n",(0,i.kt)("inlineCode",{parentName:"p"},"GRCh38_no_alt")," analysis set."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz -O GRCh38_no_alt.fa.gz\ngunzip GRCh38_no_alt.fa.gz\n")),(0,i.kt)("h2",{id:"index-the-reference-genome"},"Index the reference genome"),(0,i.kt)("p",null,"Once you've downloaded the reference FASTA, you'll need to create the data\nstructure needed for the ",(0,i.kt)("inlineCode",{parentName:"p"},"bwa")," alignment algorithm. You can do this by running\nthe ",(0,i.kt)("inlineCode",{parentName:"p"},"bwa index")," command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"bwa index GRCh38_no_alt.fa\n# [bwa_index] Pack FASTA... 22.93 sec\n# [bwa_index] Construct BWT for the packed sequence...\n# [BWTIncCreate] textLength=6199845082, availableWord=448243540\n# [BWTIncConstructFromPacked] 10 iterations done. 99999994 characters processed.\n# [BWTIncConstructFromPacked] 20 iterations done. 199999994 characters processed.\n# [BWTIncConstructFromPacked] 30 iterations done. 299999994 characters processed.\n#\n# ----------------------\n# | Abbreviated output |\n# ----------------------\n#\n# [BWTIncConstructFromPacked] 680 iterations done. 6184133946 characters processed.\n# [bwt_gen] Finished constructing BWT in 688 iterations.\n# [bwa_index] 1753.46 seconds elapse.\n# [bwa_index] Update BWT... 11.90 sec\n# [bwa_index] Pack forward-only FASTA... 17.86 sec\n# [bwa_index] Construct SA from BWT and Occ... 780.19 sec\n# [main] Version: 0.7.17-r1188\n# [main] CMD: bwa index GRCh38_no_alt.fa\n# [main] Real time: 2597.464 sec; CPU: 2586.355 sec\n")),(0,i.kt)("h2",{id:"aligning-reads"},"Aligning reads"),(0,i.kt)("p",null,"With your reads downloaded and your reference files prepared, you are now ready\nto align reads to the human genome."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"bwa mem -t `nproc` GRCh38_no_alt.fa SRR038564_1.filt.fastq.gz SRR038564_2.filt.fastq.gz > SRR038564.bwa-mem.sam\n# [M::bwa_idx_load_from_disk] read 0 ALT contigs\n# [M::process] read 1052632 sequences (80000032 bp)...\n# [M::process] read 1052632 sequences (80000032 bp)...\n# [M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (5, 366049, 20, 5)\n# [M::mem_pestat] skip orientation FF as there are not enough pairs\n# [M::mem_pestat] analyzing insert size distribution for orientation FR...\n# [M::mem_pestat] (25, 50, 75) percentile: (379, 414, 428)\n# [M::mem_pestat] low and high boundaries for computing mean and std.dev: (281, 526)\n# [M::mem_pestat] mean and std.dev: (415.82, 26.23)\n# [M::mem_pestat] low and high boundaries for proper pairs: (232, 575)\n# [M::mem_pestat] analyzing insert size distribution for orientation RF...\n# [M::mem_pestat] (25, 50, 75) percentile: (84, 168, 372)\n# [M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 948)\n# [M::mem_pestat] mean and std.dev: (166.47, 127.04)\n# [M::mem_pestat] low and high boundaries for proper pairs: (1, 1236)\n# [M::mem_pestat] skip orientation RR as there are not enough pairs\n# [M::mem_pestat] skip orientation RF\n# [M::mem_process_seqs] Processed 1052632 reads in 232.390 CPU sec, 30.295 real sec\n#\n# ----------------------\n# | Abbreviated output |\n# ----------------------\n#\n# [M::mem_process_seqs] Processed 778766 reads in 167.751 CPU sec, 21.112 real sec\n# [main] Version: 0.7.17-r1188\n# [main] CMD: bwa mem -t 8 GRCh38_no_alt.fa SRR038564_1.filt.fastq.gz SRR038564_2.filt.fastq.gz\n# [main] Real time: 1045.858 sec; CPU: 8226.046 sec\n")),(0,i.kt)("h2",{id:"postprocessing"},"Postprocessing"),(0,i.kt)("p",null,"Once alignment has finished, you will want to do the following steps:"),(0,i.kt)("h3",{id:"coordinate-sort"},"Coordinate sort"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"samtools sort SRR038564.bwa-mem.sam > SRR038564.bwa-mem.sorted.bam\n# [bam_sort_core] merging from 10 files and 1 in-memory blocks...\n")),(0,i.kt)("h3",{id:"mark-duplicates"},"Mark duplicates"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"picard MarkDuplicates I=SRR038564.bwa-mem.sorted.bam O=SRR038564.bwa-mem.sorted.marked.bam M=SRR038564.bwa-mem.sorted.marked.bam.metrics\n# INFO  2019-11-09 23:55:27 MarkDuplicates\n#\n# ********** NOTE: Picard's command line syntax is changing.\n# **********\n# ********** For more information, please see:\n# ********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n# **********\n# ********** The command line looks like this in the new syntax:\n# **********\n# **********    MarkDuplicates -I SRR038564.bwa-mem.sorted.bam -O SRR038564.bwa-mem.sorted.marked.bam -M SRR038564.bwa-mem.sorted.marked.bam.metric\n# **********\n#\n#\n# 23:55:27.730 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/claymcleod/anaconda3/envs/bio/share/picard-2.21.2-0/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n# [Sat Nov 09 23:55:27 CST 2019] MarkDuplicates INPUT=[SRR038564.bwa-mem.sorted.bam] OUTPUT=SRR038564.bwa-mem.sorted.marked.bam METRICS_FILE=SRR038564.bwa-mem.sorted.marked.bam.metric    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false ADD_PG_TAG_TO_READS=true REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n# [Sat Nov 09 23:55:27 CST 2019] Executing as claymcleod@clay-desktop on Linux 5.0.0-32-generic amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.2-SNAPSHOT\n# INFO  2019-11-09 23:55:27 MarkDuplicates  Start of doWork freeMemory: 502091736; totalMemory: 514850816; maxMemory: 954728448\n# INFO  2019-11-09 23:55:27 MarkDuplicates  Reading input file and constructing read end information.\n# INFO  2019-11-09 23:55:27 MarkDuplicates  Will retain up to 3459161 data points before spilling to disk.\n# WARNING   2019-11-09 23:55:27 AbstractOpticalDuplicateFinderCommandLineProgram    A field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR038564.671400. Cause: String 'SRR038564.671400' did not start with a parsable number.\n# INFO  2019-11-09 23:55:30 MarkDuplicates  Read     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: chr1:81,034,799\n# INFO  2019-11-09 23:55:30 MarkDuplicates  Tracking 20709 as yet unmatched pairs. 1329 records in RAM.\n# INFO  2019-11-09 23:55:32 MarkDuplicates  Read     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: chr1:167,422,460\n# INFO  2019-11-09 23:55:32 MarkDuplicates  Tracking 42081 as yet unmatched pairs. 1540 records in RAM.\n# INFO  2019-11-09 23:55:35 MarkDuplicates  Read     3,000,000 records.  Elapsed time: 00:00:07s.  Time for last 1,000,000:    2s.  Last read position: chr2:5,004,404\n#\n# ----------------------\n# | Abbreviated output |\n# ----------------------\n#\n# INFO  2019-11-09 23:57:09 MarkDuplicates  Read    34,000,000 records.  Elapsed time: 00:01:41s.  Time for last 1,000,000:    2s.  Last read position: chrX:127,198,460\n# INFO  2019-11-09 23:57:09 MarkDuplicates  Tracking 61894 as yet unmatched pairs. 6106 records in RAM.\n# INFO  2019-11-09 23:57:13 MarkDuplicates  Read 34964531 records. 0 pairs never matched.\n# INFO  2019-11-09 23:57:14 MarkDuplicates  After buildSortedReadEndLists freeMemory: 1043659632; totalMemory: 1054343168; maxMemory: 1054343168\n# INFO  2019-11-09 23:57:14 MarkDuplicates  Will retain up to 32948224 duplicate indices before spilling to disk.\n# INFO  2019-11-09 23:57:14 MarkDuplicates  Traversing read pair information and detecting duplicates.\n# INFO  2019-11-09 23:57:18 MarkDuplicates  Traversing fragment information and detecting duplicates.\n# INFO  2019-11-09 23:57:23 MarkDuplicates  Sorting list of duplicate records.\n# INFO  2019-11-09 23:57:23 MarkDuplicates  After generateDuplicateIndexes freeMemory: 787714176; totalMemory: 1062207488; maxMemory: 1062207488\n# INFO  2019-11-09 23:57:23 MarkDuplicates  Marking 4432335 records as duplicates.\n# INFO  2019-11-09 23:57:23 MarkDuplicates  Found 0 optical duplicate clusters.\n# INFO  2019-11-09 23:57:23 MarkDuplicates  Reads are assumed to be ordered by: coordinate\n# INFO  2019-11-09 23:58:08 MarkDuplicates  Written    10,000,000 records.  Elapsed time: 00:00:45s.  Time for last 10,000,000:   45s.  Last read position: chr4:174,112,624\n# ^[INFO    2019-11-09 23:58:53 MarkDuplicates  Written    20,000,000 records.  Elapsed time: 00:01:30s.  Time for last 10,000,000:   44s.  Last read position: chr10:71,662,147\n# INFO  2019-11-09 23:59:39 MarkDuplicates  Written    30,000,000 records.  Elapsed time: 00:02:16s.  Time for last 10,000,000:   46s.  Last read position: chr18:69,528,922\n# INFO  2019-11-10 00:00:09 MarkDuplicates  Writing complete. Closing input iterator.\n# INFO  2019-11-10 00:00:09 MarkDuplicates  Duplicate Index cleanup.\n# INFO  2019-11-10 00:00:09 MarkDuplicates  Getting Memory Stats.\n# INFO  2019-11-10 00:00:09 MarkDuplicates  Before output close freeMemory: 1061636408; totalMemory: 1073217536; maxMemory: 1073217536\n# INFO  2019-11-10 00:00:09 MarkDuplicates  Closed outputs. Getting more Memory Stats.\n# INFO  2019-11-10 00:00:09 MarkDuplicates  After output close freeMemory: 1061636408; totalMemory: 1073217536; maxMemory: 1073217536\n# [Sun Nov 10 00:00:09 CST 2019] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 4.70 minutes.\n# Runtime.totalMemory()=1073217536\n")),(0,i.kt)("h3",{id:"index-the-bam-file"},"Index the BAM file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"samtools index SRR038564.bwa-mem.sorted.marked.bam\n")),(0,i.kt)("h3",{id:"sanity-flagstat-check"},"Sanity Flagstat Check"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"samtools flagstat SRR038564.bwa-mem.sorted.marked.bam\n# 37653971 + 0 in total (QC-passed reads + QC-failed reads)\n# 0 + 0 secondary\n# 33085 + 0 supplementary\n# 4432335 + 0 duplicates\n# 34674582 + 0 mapped (92.09% : N/A)\n# 37620886 + 0 paired in sequencing\n# 18810443 + 0 read1\n# 18810443 + 0 read2\n# 27610948 + 0 properly paired (73.39% : N/A)\n# 34351548 + 0 with itself and mate mapped\n# 289949 + 0 singletons (0.77% : N/A)\n# 815158 + 0 with mate mapped to a different chr\n# 440386 + 0 with mate mapped to a different chr (mapQ>=5)\n")),(0,i.kt)("h2",{id:"piling-up-variants"},"Piling up variants"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# You can split these commands up, but the output of the first command is several hundred GB.\nbcftools mpileup -Ou SRR038564.bwa-mem.sorted.marked.bam -f GRCh38_no_alt.fa --threads `nproc` | bcftools call -mv > SRR038564.called.vcf\n")),(0,i.kt)("h2",{id:"number-of-variants"},"Number of variants"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'grep -v "^#" SRR038564.called.vcf | wc -l\n# 1391682\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"bcftools view -i '%QUAL>=20' SRR038564.called.vcf | wc -l\n# 279547\n")),(0,i.kt)("h2",{id:"download-igv"},"Download IGV"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://software.broadinstitute.org/software/igv/download"},"https://software.broadinstitute.org/software/igv/download")))}u.isMDXComponent=!0}}]);